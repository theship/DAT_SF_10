{
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## General Assembly Data Science, San Francisco\n",
      "## github.com/ga-students/DAT_SF_10\n",
      "##\n",
      "## Julee Burdekin\n",
      "## juburdekin@gmail.com\n",
      "##\n",
      "## 20141020\n",
      "## HW2\n",
      "##\n",
      "## Deep, hands-on experience with cross validation and selection of model parameters.\n",
      "## Although the Scikitlearn package provides packaged methods, crossvalidation is such \n",
      "## an important concept that will will implement it ourselves in this assignment.\n",
      "## We will then use our implementation of cross validation to select some model paraters -\n",
      "## also called hyperparamters 0 for our KNN classifier on the Iris dataset.\n",
      "\n",
      "## QUESTION 1: Implement KNN classification, using the sklearn package. We learned how to do this in class.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn import datasets\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.ticker import FormatStrFormatter\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "feature_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "\n",
      "iris = pd.read_csv('iris.csv', names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target_names'])\n",
      "\n",
      "'''\n",
      "type(iris)\n",
      "iris.keys()\n",
      "print iris.info()\n",
      "'''\n",
      "print iris.describe()\n",
      "'''\n",
      "print iris.keys()\n",
      "'''\n",
      "\n",
      "iris = iris.dropna()\n",
      "X = iris.as_matrix(feature_names).astype(float)\n",
      "y = iris.as_matrix(['target_names']).astype(str)\n",
      "y = np.ravel(y)\n",
      "\n",
      "## split the data into training set and test set\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)\n",
      "\n",
      "# Train KNN classifier defined function on the train data\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "myknn = KNeighborsClassifier(3).fit(X_train,y_train)\n",
      "knnScore = myknn.score(X_test, y_test)\n",
      "\n",
      "print knnScore\n",
      "\n",
      "## QUESTION 2: Implement cross-validation for your KNN classifier.\n",
      "\n",
      "# generic cross validation function\n",
      "def cross_validate(X, y, classifier, k_fold):\n",
      "\n",
      "    # derive a set of (random) training and testing indices\n",
      "    k_fold_indices = KFold( len(X), n_folds=k_fold,\n",
      "                           indices=True, shuffle=True,\n",
      "                           random_state=0)\n",
      "\n",
      "    k_score_total = 0\n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices:\n",
      "\n",
      "        model = classifier(X[ train_slice  ],\n",
      "                         y[ train_slice  ])\n",
      "\n",
      "        k_score = model.score(X[ test_slice ],\n",
      "                              y[ test_slice ])\n",
      "\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    averAccuracy =  k_score_total/k_fold\n",
      "\n",
      "    return averAccuracy\n",
      "\n",
      "print cross_validate(X, y, KNeighborsClassifier(3).fit, 5)\n",
      "\n",
      "## QUESTION 3: Use your knn classifier (knnScore) and xvalidation code from Q1&2 (averAccuracy), above\n",
      "## to get optimal K (# of nearest neighbors to consult)\n",
      "\n",
      "knn_values = np.array(range(1,120))\n",
      "knn_results = []\n",
      "for points in range(1,120):\n",
      "    knn_results.append(cross_validate(X, y, KNeighborsClassifier(points).fit, 5))\n",
      "\n",
      "maxK = max(knn_results)\n",
      "minK = min(knn_results)\n",
      "meanK = np.array(knn_results).mean()\n",
      "optimalK_max = knn_results.index(maxK)\n",
      "\n",
      "print \"The top k most similar pieces of data from our known dataset is:\"\n",
      "print optimalK_max\n",
      "print \"But, I am not sure what I'm doing here...\"\n",
      "\n",
      "## QUESTION 4: Use matplotlib to plot classifier accuracy vs. hyperparameter K\n",
      "## for a range of K that you consider interesting - & explain\n",
      "\n",
      "plt.plot(knn_results)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}